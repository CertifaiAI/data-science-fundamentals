{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Copyright (c) 2020-2021 CertifAI Sdn. Bhd.\n",
    "# \n",
    "# This program is part of OSRFramework. You can redistribute it and/or modify\n",
    "# it under the terms of the GNU Affero General Public License as published by\n",
    "# the Free Software Foundation, either version 3 of the License, or\n",
    "# (at your option) any later version.\n",
    "# \n",
    "# This program is distributed in the hope that it will be useful,\n",
    "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "# GNU Affero General Public License for more details.\n",
    "# \n",
    "# You should have received a copy of the GNU Affero General Public License\n",
    "# along with this program.  If not, see <http://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "Decision Trees (DTs) are a supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.\n",
    "\n",
    "## Random Forest\n",
    "\n",
    "A **random forest** is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. \n",
    "\n",
    "Random Forest classifier is a type of ensemble learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Decision Tree for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iris.data.astype(np.float32)\n",
    "target = iris.target.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.(\n",
    "    data, target, test_size=0.3, random_state=123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(criterion='entropy', random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default parameters\n",
    "\n",
    "#### criterion='entropy'\n",
    "Evaluate feature importance. 'entropy' algorithm is based on Information theory which is a method to quantify information in a message. In our example, it is used to quantify the information of the data to make decision and split the node.\n",
    "\n",
    "#### min_samples_leaf=1\n",
    "Minimum number of sample(s) to qualify as leaf node\n",
    "\n",
    "#### min_samples_split=2\n",
    "Minimum number of sample(s) to qualify for internal node split\n",
    "\n",
    "#### splitter='best'\n",
    "Method used by the model to make decision when splitting. 'best' method will tell the model to consider feature with highest importance\n",
    "\n",
    "#### random_state=0\n",
    "Seed to generate random number by the model. Will effect any randomness from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_tree(classifier):\n",
    "    fig, axes = plt.subplots(nrows=1,ncols=1,figsize=(4,4), dpi=150) #change dpi to resize image\n",
    "    tree_view = plot_tree(classifier, feature_names=iris.feature_names,\n",
    "              class_names=iris.target_names, ax=axes, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_tree(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The color filled indicate the majority class for classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Random Forest for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default parameters\n",
    "\n",
    "#### bootstrap=True\n",
    "Decide if the model will use all or different(random) number of sample for every tree. If true, the model randomly choose number of samples for every tree.\n",
    "\n",
    "#### max_features='auto'\n",
    "Decide the number of features to conisder for best split. 'auto' will use sqrt(n_features) for making decision\n",
    "\n",
    "#### min_samples_leaf=1\n",
    "Minimum number of sample(s) to qualify as leaf node\n",
    "\n",
    "#### min_samples_split=2\n",
    "Minimum number of sample(s) to qualify for internal node split\n",
    "\n",
    "#### n_estimators=10\n",
    "Decide the number of decision tree. This is important as RandomForest uses multiple decision trees.\n",
    "\n",
    "#### verbose=0\n",
    "To view training information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View trees\n",
    "RandomForest algorithm is a combination of few decision trees. Therefore, every tree should be plot individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees\n",
    "num_trees = len(classifier.estimators_)\n",
    "print(num_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_trees):\n",
    "    if i > 2: #Only plot the first 3 trees\n",
    "        break\n",
    "    view_tree(classifier.estimators_[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different trees provide different decision branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "def plot_cm(y_test, predictions, figsize):\n",
    "    cm = confusion_matrix(y_test,predictions)\n",
    "    df_cm = pd.DataFrame(cm)\n",
    "    df_cm.index.name = 'Actual'\n",
    "    df_cm.columns.name = 'Predicted'\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.set(font_scale=1.4)\n",
    "    sns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 16},\n",
    "               fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(y_test, predictions, figsize=(7, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Interpretation - Confusion Matrix\n",
    "\n",
    "predicted axis: the result of model prediction\n",
    "actual axis: actual ground truth\n",
    "\n",
    "The desired result is for the prediction to be the same as actual. From the matrix, we can see that the model predict 100% correct for item 0 and 2 and produce two wrong predictions for item 1. The confusion matrix provides useful information for model bias, as in, what is the tendency of the model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Interpretaion - Classification Report\n",
    "\n",
    "#### Precision\n",
    "The percentage of correct predictions. Like the confusion matrix, you can see that item 0 and 2 is correctly predicted 100%.\n",
    "\n",
    "#### Recall\n",
    "Ability of the classifier to find all positive instances. Look from actual axis for item 2. The model find positive instances 15 times out of total instances of 17. This is 88% of the total.\n",
    "\n",
    "#### F1-Score\n",
    "The weighted average of the precision and recall. \n",
    "\n",
    "<img src=\"https://miro.medium.com/max/752/1*UJxVqLnbSj42eRhasKeLOA.png\" />\n",
    "\n",
    "[Image Source: Towards Data Science](https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c#:~:text=We%20use%20the%20harmonic%20mean%20instead%20of%20a%20simple%20average)\n",
    "\n",
    "#### Support \n",
    "Total number of occurences of given class. We call them item in this example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 news Group Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_categories = ['comp.graphics','comp.os.ms-windows.misc',\n",
    "                   'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware',\n",
    "                   'comp.windows.x']\n",
    "\n",
    "ng = datasets.fetch_20newsgroups(categories=news_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html for full news categories. We will only use some in this example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng.data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_class = ng.target[:1]\n",
    "\n",
    "# Let's see which class does the news belong.\n",
    "print(news_class)\n",
    "\n",
    "# Let's convert the index to string label\n",
    "print(ng.target_names[news_class[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation 1 : Vectorizing\n",
    "\n",
    "Sklearn algorithm cannot process strings. Because our data is in string format, it needs to be converted to numbers. This process is called vectorizing.\n",
    "\n",
    "There are lots of vectorizing algorithm. For now, we are going to use a simple algorithm called CountVectorier. This algorithm converts the data into a matrix of token counts. A token is a single word. A sentence with five words has 5 tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "data = vectorizer.fit_transform(ng.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have the right format. The data has 11314 sentences and 130107 vocabulary. Wow! That's a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat1 = data[1,:].toarray()\n",
    "dat1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every sentence in the dataset is converted to a vector of length 66735. The value of each element indicate the total occurence of a particular word in the sentence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation 2 : Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target to numpy float\n",
    "\n",
    "target = ng.target.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    data, target, test_size=0.3, random_state=123\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize sklearn decision tree classifier using entropy criterion and random state of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(y_test, predictions, figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said before, it is desired that the diagonal be the most significant number for the particular column.\n",
    "\n",
    "However, in this example, the model does not classify the data well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the accuracy of model accorss all class is only 65%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train sklearn random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform evaluation by showing confusion matrix and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we are using the default value, the model performs well with 69% accuracy.\n",
    "\n",
    "The model can be improved by performing a grid search to find the best hyperparameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
