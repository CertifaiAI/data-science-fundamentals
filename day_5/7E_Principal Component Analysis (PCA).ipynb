{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "![license_header_logo](https://user-images.githubusercontent.com/59526258/124226124-27125b80-db3b-11eb-8ba1-488d88018ebb.png)\r\n",
    "> **Copyright (c) 2020-2021 CertifAI Sdn. Bhd.**<br>\r\n",
    " <br>\r\n",
    "This program is part of OSRFramework. You can redistribute it and/or modify\r\n",
    "<br>it under the terms of the GNU Affero General Public License as published by\r\n",
    "<br>the Free Software Foundation, either version 3 of the License, or\r\n",
    "<br>(at your option) any later version.\r\n",
    "<br>\r\n",
    "<br>This program is distributed in the hope that it will be useful,\r\n",
    "<br>but WITHOUT ANY WARRANTY; without even the implied warranty of\r\n",
    "<br>MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\r\n",
    "<br>GNU Affero General Public License for more details.\r\n",
    "<br>\r\n",
    "<br>You should have received a copy of the GNU Affero General Public License\r\n",
    "<br>along with this program.  If not, see <http://www.gnu.org/licenses/>.\r\n",
    "<br>"
   ],
   "metadata": {
    "deletable": false,
    "editable": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Iris dataset Data Visualization using Principal Component Analysis(PCA)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "In PCA, we are trying to reduce the dimensions of a dataset when the features become to vast for comprehension and cannot decide which feature to choose. PCA is preferrable when you want to visualize your data, or to help your machine learning model to improve.\n",
    ">**Rule of thumb to choose PCA**: <br><br>\n",
    ">1.Do you want to reduce the number of variables, but arenâ€™t able to identify variables to completely remove from consideration?<br>\n",
    ">2.Do you want to ensure your variables are independent of one another?<br>\n",
    ">3.Are you comfortable making your independent variables less interpretable?<br><br>\n",
    ">If yes to all, PCA is the right method. If no to question 3, PCA might not be your ideal solution.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd \r\n",
    "import numpy as np\r\n",
    "from sklearn.decomposition import PCA\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn import datasets\r\n",
    "from sklearn import model_selection\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Data\n",
    "Here we will load the IRIS dataset from **scikit-learn**. We will be utilizing `iris.data` and `iris.target` as usual for our features and values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "iris = datasets.load_iris()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As usual `dir(iris)` shows the attributes of the iris datasets.<br> \n",
    "- `iris.data.shape` shows the shape of the data.<br>\n",
    "- `iris.target_names` shows the classes that we want to classify.<br>\n",
    "- `iris.feature_names` shows the name of features that we are training."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dir(iris)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "iris.target_names"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "iris.feature_names"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "iris.data.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.unique(iris.target)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = iris.data.astype(np.float32)\n",
    "target = iris.target.astype(np.float32)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame(data=data, columns=iris.feature_names).head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use StandardScaler to scale the data before applying PCA.<br>\n",
    "<i>Hint: data is usually split before we scale them, but for ease, we will not scale it here"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scaled_data = Standard().fit_transform(data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame(data=scaled_data, columns=iris.feature_names).head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To help visualize our data, we will reduce the number of dimensions of our data into 2.<br>\n",
    "Specify the target number of **principal components** to 2."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO: Set Principal Components = 2\n",
    "pca = PCA(n_components)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "principal_components = pca.fit_transform(scaled_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "principaldf = pd.DataFrame(data=principal_components,\n",
    "                           columns=['Principal component 1', 'Principal component 2'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In PCA, we are trying to reduce the dimensions of the data. While it is reducing the dimensions, PCA tries to retain as much information as possible from those columns(dimensions) that are dropped.<br><br>\n",
    "\n",
    "We are not going to bore you with the gory details of the math, those who are interested may refer below for more insights to PCA, but in layman terms, we are only interested in the data that has the most variability. The higher the variability of the data, the more information we have. <br><br> \n",
    "Basically, PCA will come up with principal components which are mostly dimensions with the highest variance while still retaining some of the information of the dropped columns.<br><br>\n",
    "In this case, **Principal component 1** and **Principal component 2** are the resulting new dimensions that are produce largely according to the 2 highest variances of the original dimensions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "principaldf.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "targetdf = pd.DataFrame(data=iris.target,\n",
    "                        columns=[\"Iris Class\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "finaldf = pd.concat([principaldf, targetdf], axis=1)\n",
    "finaldf.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Specify the **targets** to be the **labels** of the iris dataset.<br>\n",
    "Visualize the 2 principal components using **`pyplot`**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO: Set targets to be labels of the plot\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize=13)\n",
    "ax.set_ylabel('Principal Component 2', fontsize=13)\n",
    "ax.set_title('2D Data Visualization after PCA', fontsize=15)\n",
    "\n",
    "targets=np.unique(iris.)\n",
    "\n",
    "colors = ['b', 'g', 'r']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finaldf[\"Iris Class\"] == target\n",
    "    ax.scatter(finaldf.loc[indicesToKeep, 'Principal component 1'],\n",
    "               finaldf.loc[indicesToKeep, 'Principal component 2'],\n",
    "               c=color,\n",
    "               s=50)\n",
    "ax.legend(iris.target_names)\n",
    "ax.grid()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**explained_variance_ratio_** : array, shape (n_components,)\n",
    "Percentage of variance explained by each of the selected components.\n",
    "\n",
    "If n_components is not set then all components are stored and the sum of the ratios is equal to 1.0."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print out the variance ratio."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO: complete the code to print variance ratio\n",
    "pca._"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After PCA, Dimension of the dataset was reduced from four to two. Using **`pca.explained_variance_ratio`**, we can see how much variance of the total variance was retained. Higher percentages will mean that more information is retained.\n",
    "\n",
    "0.7296+0.2285=0.9581.\n",
    "\n",
    "**95.81%** of the information was retained."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us try with another dataset, this time we will use the famous Breast Cancer dataset.\n",
    "We can load it directly from scikit-learn."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Breast Cancer Data Visualization using PCA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bcancer=datasets.load_breast_cancer()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dir(bcancer)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's check how many class do we have in this dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bcancer.target_names"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are **two** target classes in the breast cancer dataset, Malignant and Benign.\n",
    "\n",
    "**Malignant** means **\"Harmful\"** whereas **Benign** means **\"Not Harmful\"**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bcancer.feature_names"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bcancer.data.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the breast cancer dataset, there are 30 features or columns of data.\n",
    "\n",
    "There are 569 rows of sample data or entries."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = bcancer.data.astype(np.float32)\n",
    "target = bcancer.target.astype(np.float32)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.unique(bcancer.target)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame(data = data, columns = bcancer.feature_names).head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Scale** the data before applying PCA."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO: \n",
    "scaled_data = StandardScaler().(data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame(data = scaled_data, columns = bcancer.feature_names).head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pca = (n_components=2)\n",
    "principal_components = pca.fit_transform(scaled_data)\n",
    "principaldf = pd.DataFrame(data=principal_components, \n",
    "                           columns=['Principal component 1', 'Principal component 2'])\n",
    "principaldf.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "targetdf = pd.DataFrame(data=bcancer.target,\n",
    "                        columns=[\"Breast Cancer Class\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "finaldf = pd.concat([principaldf, targetdf], axis = 1)\n",
    "finaldf.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Specify the \"targets\" to be the labels of the breast cancer dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO: Complete the code to specify targets\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 13)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 13)\n",
    "ax.set_title('2D Data Visualization after PCA', fontsize = 15)\n",
    "\n",
    "=np.unique(bcancer.target)\n",
    "\n",
    "colors = ['r', 'b']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finaldf[\"Breast Cancer Class\"] == target\n",
    "    ax.scatter(finaldf.loc[indicesToKeep, 'Principal component 1'],\n",
    "               finaldf.loc[indicesToKeep, 'Principal component 2'],\n",
    "               c = color,\n",
    "               s = 50)\n",
    "ax.legend(bcancer.target_names)\n",
    "ax.grid()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print out the variance ratio."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO: Complete the command to print out variance ratio\n",
    ".explained_variance_ratio_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "After PCA, Dimension of the dataset was reduced from **thirty to two**.<br><br>\n",
    "The more the difference between the initial and final dimensions, it is inevitable that the information retained will be less.\n",
    "\n",
    "0.4427+0.1897=0.6324.\n",
    "\n",
    "**63.24%** of the information was retained."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Despite the information lost, we can still see that the two classes of Breast Cancer is **clearly separated** by using the provided dataset."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}