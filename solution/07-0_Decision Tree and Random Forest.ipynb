{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "Decision Trees (DTs) are a supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.\n",
    "\n",
    "## Random Forest\n",
    "\n",
    "A **random forest** is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. \n",
    "\n",
    "Random Forest classifier is a type of ensemble learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Decision Tree for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iris.data.astype(np.float32)\n",
    "target=iris.target.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    data, target, test_size=0.3, random_state=123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  3 14]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        18\n",
      "         1.0       0.77      1.00      0.87        10\n",
      "         2.0       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.92      0.94      0.92        45\n",
      "weighted avg       0.95      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Random Forest for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  2 15]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        18\n",
      "         1.0       0.83      1.00      0.91        10\n",
      "         2.0       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.94      0.96      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 news Group Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng = datasets.fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\"]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng.data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\n",
      "rec.autos\n"
     ]
    }
   ],
   "source": [
    "news_class = ng.target[:1]\n",
    "\n",
    "# Let's see which class does the news belong.\n",
    "print(news_class)\n",
    "\n",
    "# Let's convert the index to string label\n",
    "print(ng.target_names[news_class[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sound fine, the news definitely talk about car which is of autos class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation 1 : Vectorizing\n",
    "\n",
    "Algorithm cannot process string. Because our data is in string format, it need to be converted to numbers. This process is called vectorizing.\n",
    "\n",
    "There are lots of vectorizing algorithm. For now, we are going to use a simple algorithm called CountVectorier. This algorithm converts the data into a matrix of token counts. Token is a single word. A sentence with 5 words have 5 tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "data = vectorizer.fit_transform(ng.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11314x130107 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1787565 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have the right format. The data has 11314 sentences and 130107 vocabulary. Wow! That's a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation 2 : Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target to numpy float\n",
    "\n",
    "target = ng.target.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    data, target, test_size=0.3, random_state=123\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 59   3   1   1   5   2   2   0   1   4   3   0   3   6   1   7   2   5\n",
      "    6  16]\n",
      " [  3  46  16  11  11  13   8   5   3   8   5   7  12  10   2   5   2   2\n",
      "    1   1]\n",
      " [  1  10  97  19   3  11   4   1   1   4   0   5   9   6   7   2   0   0\n",
      "    1   1]\n",
      " [  3  13  15  43  11   7   6   4   5   1   5   2  18   6   3  10   1   1\n",
      "    1   3]\n",
      " [  2  10   7  14  64   4  11   7   4   7   2   2  12   8   7   8   3   1\n",
      "    4   3]\n",
      " [  2  35  11  18   3  64   5   6   3   2   3   5  19   8   6   5   1   3\n",
      "    1   0]\n",
      " [  0   4   3  12   5   3 112   3   6   4   1   2   4   4   4   5   1   0\n",
      "    1   0]\n",
      " [  3   8   1   5   6   5   2  94   9   4   4   1   8   7   4   0   3   6\n",
      "    4   5]\n",
      " [  2   3   2   6   3   5   5   7 109   2   5   0   4   5   1   2   3   1\n",
      "    1   3]\n",
      " [  1   8   2   3   6   3   4   4   3  93  22   0   6   6   5   6   6   3\n",
      "    3   2]\n",
      " [  1   5   2   1   0   3   6   3   2  21  92   3   6   1   1   0   4   0\n",
      "    5   3]\n",
      " [  0  10   1   4   6   4   1   0   2   1   3 142   6   5   2   2   7   0\n",
      "    8   2]\n",
      " [  3  16  13  18   8  14   6  14   7   3   4   2  39  13   7   4   3   3\n",
      "    5   7]\n",
      " [  3   7   5   4   2   9   5   4   3   3   5   1   8  69   7  11   1   3\n",
      "   12   5]\n",
      " [  4   6   4   4   4   1   2   5   2   4   5   4   6  16  80   5   5   6\n",
      "    9   5]\n",
      " [ 16   6   0   5   3   2   2   4   2   3   2   2   7   8   3 108   2   1\n",
      "    4  19]\n",
      " [  4   4   2   1   3   0   4   6   2   4   1   5   8   7   2   4  86   4\n",
      "    7  11]\n",
      " [  5   4   1   4   2   1   2   3   1   3   6   2   2   4   1   2   3 108\n",
      "    4  11]\n",
      " [  6   2   2   1   3   1   2   5   1   2   3   1   2   8   5   7  19   5\n",
      "   45  10]\n",
      " [ 15   5   0   2   2   2   1   4   1   2   4   0   1  12   2   8   4   3\n",
      "    3  37]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.44      0.46      0.45       127\n",
      "         1.0       0.22      0.27      0.24       171\n",
      "         2.0       0.52      0.53      0.53       182\n",
      "         3.0       0.24      0.27      0.26       158\n",
      "         4.0       0.43      0.36      0.39       180\n",
      "         5.0       0.42      0.32      0.36       200\n",
      "         6.0       0.59      0.64      0.62       174\n",
      "         7.0       0.53      0.53      0.53       179\n",
      "         8.0       0.65      0.64      0.65       169\n",
      "         9.0       0.53      0.50      0.52       186\n",
      "        10.0       0.53      0.58      0.55       159\n",
      "        11.0       0.76      0.69      0.72       206\n",
      "        12.0       0.22      0.21      0.21       189\n",
      "        13.0       0.33      0.41      0.37       167\n",
      "        14.0       0.53      0.45      0.49       177\n",
      "        15.0       0.54      0.54      0.54       199\n",
      "        16.0       0.55      0.52      0.54       165\n",
      "        17.0       0.70      0.64      0.67       169\n",
      "        18.0       0.36      0.35      0.35       130\n",
      "        19.0       0.26      0.34      0.29       108\n",
      "\n",
      "    accuracy                           0.47      3395\n",
      "   macro avg       0.47      0.46      0.46      3395\n",
      "weighted avg       0.48      0.47      0.47      3395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[106   0   0   0   3   0   0   2   0   0   1   0   1   1   1   7   0   0\n",
      "    0   5]\n",
      " [  1 121  20   5   6   9   5   0   0   1   1   1   0   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   8 150  10   3   5   3   0   0   1   0   0   1   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   7  15 112   6   4   5   0   0   0   1   3   3   0   1   1   0   0\n",
      "    0   0]\n",
      " [  0   5   3  21 135   1  11   0   0   1   0   0   1   1   0   0   0   1\n",
      "    0   0]\n",
      " [  0  15  16  12   0 151   1   1   0   2   0   0   0   0   2   0   0   0\n",
      "    0   0]\n",
      " [  0   0   2   6   1   0 156   0   0   3   2   0   0   2   0   0   0   1\n",
      "    0   1]\n",
      " [  0   3   4   3   2   1   4 155   5   1   1   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   1   0   0   1   0   4   3 156   0   0   0   0   1   0   1   1   0\n",
      "    0   0]\n",
      " [  1   3   0   0   2   0   3   2   0 163  10   0   2   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1   1   0   2 153   0   0   2   0   0   0   0\n",
      "    0   0]\n",
      " [  1   2   2   1   0   2   1   0   0   0   0 195   1   0   0   0   0   0\n",
      "    1   0]\n",
      " [  0   3   5  18   6   1  11   4   4   0   1   2 124   6   2   1   0   0\n",
      "    1   0]\n",
      " [  0   5   2   2   1   4   6   1   0   1   0   0   2 139   2   2   0   0\n",
      "    0   0]\n",
      " [  0   2   1   1   1   1   2   0   0   1   1   1   2   0 162   1   1   0\n",
      "    0   0]\n",
      " [  0   1   0   2   1   0   0   1   0   3   0   0   0   1   0 183   0   4\n",
      "    1   2]\n",
      " [  1   1   1   0   1   0   0   0   0   0   1   2   0   0   1   0 152   2\n",
      "    3   0]\n",
      " [  0   1   0   0   2   0   0   0   0   0   1   0   1   0   2   2   0 160\n",
      "    0   0]\n",
      " [  2   1   0   1   0   0   1   0   0   2   0   0   2   2   0   4  11   2\n",
      "  101   1]\n",
      " [  9   1   0   1   2   0   0   3   1   1   0   0   2   2   2  34   4   1\n",
      "    1  44]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.83      0.85       127\n",
      "         1.0       0.67      0.71      0.69       171\n",
      "         2.0       0.68      0.82      0.74       182\n",
      "         3.0       0.57      0.71      0.63       158\n",
      "         4.0       0.78      0.75      0.76       180\n",
      "         5.0       0.84      0.76      0.80       200\n",
      "         6.0       0.73      0.90      0.80       174\n",
      "         7.0       0.90      0.87      0.88       179\n",
      "         8.0       0.94      0.92      0.93       169\n",
      "         9.0       0.90      0.88      0.89       186\n",
      "        10.0       0.88      0.96      0.92       159\n",
      "        11.0       0.96      0.95      0.95       206\n",
      "        12.0       0.87      0.66      0.75       189\n",
      "        13.0       0.89      0.83      0.86       167\n",
      "        14.0       0.92      0.92      0.92       177\n",
      "        15.0       0.78      0.92      0.84       199\n",
      "        16.0       0.90      0.92      0.91       165\n",
      "        17.0       0.94      0.95      0.94       169\n",
      "        18.0       0.94      0.78      0.85       130\n",
      "        19.0       0.83      0.41      0.55       108\n",
      "\n",
      "    accuracy                           0.83      3395\n",
      "   macro avg       0.84      0.82      0.82      3395\n",
      "weighted avg       0.84      0.83      0.83      3395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
