{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![license_header_logo](https://user-images.githubusercontent.com/59526258/124226124-27125b80-db3b-11eb-8ba1-488d88018ebb.png)\n",
    "> **Copyright (c) 2020-2021 CertifAI Sdn. Bhd.**<br>\n",
    " <br>\n",
    "This program is part of OSRFramework. You can redistribute it and/or modify\n",
    "<br>it under the terms of the GNU Affero General Public License as published by\n",
    "<br>the Free Software Foundation, either version 3 of the License, or\n",
    "<br>(at your option) any later version.\n",
    "<br>\n",
    "<br>This program is distributed in the hope that it will be useful,\n",
    "<br>but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "<br>MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "<br>GNU Affero General Public License for more details.\n",
    "<br>\n",
    "<br>You should have received a copy of the GNU Affero General Public License\n",
    "<br>along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Feature engineering is a machine learning techniques for extracting new features from raw data.\n",
    "In this notebook, we will explore on different types of feature engineering techniques:\n",
    "1. Imputation\n",
    "2. One-hot encoding for categorical data.\n",
    "3. Categorize numerical data.\n",
    "4. Engineer outlier\n",
    "\n",
    "# Learning Outcome\n",
    "By the end of this notebook, you should be able to know on how to:\n",
    "1. Perform feature engineering for missing values. \n",
    "2. Handling categorical data (binary, nominal, ordinal)\n",
    "3. Implement feature engineering for numerical data.\n",
    "4. Handling outlier values\n",
    "\n",
    "# Table Of Contents\n",
    "* [Missing values](#missing)\n",
    "* [Categorical data](#category)\n",
    "* [Numerical data](#numeric)\n",
    "* [Outlier](#outlier)\n",
    "* [Exercise ](#exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset of employee\n",
    "df = pd.DataFrame({\n",
    "    \"Employee ID\" : ['100', '101', '102', '103', '104', '105', '106', '107', '108', '109'],\n",
    "    \"Department\" : [\"Finance\", \"IT\", \"Sales\", \"Human Resource\", \"Finance\", \"IT\", \"Sales\", \"Finance\", \"Sales\", \"IT\"],\n",
    "    \"Age\" : [24, np.nan, 18, 28, 29, 28, 30, 35, np.nan, 35],\n",
    "    \"Gender\" : [\"F\", \"M\", \"F\", \"F\", \"F\", \"M\", \"M\", \"M\", \"F\", \"F\"],\n",
    "    \"Education\" : [\"Diploma\", \"Diploma\", \"SPM\", \"Degree\", \"Degree\", \"SPM\", \"Degree\", \"SPM\", \"Diploma\", \"Degree\"]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Employee ID as int data type\n",
    "df['Employee ID'] = df['Employee ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"typeformat\">Missing Values\n",
    "\n",
    "There are two methods to handle missing values:\n",
    "1. <b>Delete information</b> that has missing value in it\n",
    "    * Delete entire column\n",
    "    * Delete entire rows\n",
    "    \n",
    "    \n",
    "2. <b>Imputation</b>\n",
    "    * Impute using mean \n",
    "    * Impute using mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the value that has missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting value\n",
    "Delete certain row or column with missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_column = df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_column.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_row = df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_row.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation\n",
    "Replace missing data with statistical estimates or frequently occured value of the variable. \n",
    "\n",
    "Numerical value:\n",
    "1. Mean\n",
    "2. Mode\n",
    "3. Median\n",
    "\n",
    "Categorical value:\n",
    "1. Frequently use value or mode imputation.\n",
    "2. Adding a \"missing\"/\"unknown\" category.\n",
    "\n",
    "In this exercise we will show on how to impute missing values by using mean or mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean\n",
    "Fill up the missing value with mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df.fillna(df.mean().astype(int)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode\n",
    "Fill up the missing value with mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = df.fillna(df.mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"category\">Categorical data\n",
    "Carry out feature engineering process on binary, nominal and ordinal categorical column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print unique value of cat_df\n",
    "for i in df.columns:\n",
    "    if df.dtypes[i] == 'object':\n",
    "        print(\"Column: {}\".format(i))\n",
    "        print(df[i].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result above, here is the list of categorical data:\n",
    "* Binary : Gender\n",
    "* Nominal : Department\n",
    "* Ordinal : Education"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Data\n",
    "Perform one-hot encoding by using `pd.get_dummies`. It converts categorical variable into dummy/indicator variables for each category.<br>\n",
    "\n",
    "The column for the first category of our data will be removed by using the `drop_first=True` because it will contain the same information as the new column of the second category or for multiple categories, its information will be captured in the rest of the columns. It will be removed to prevent data redundancy in out dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data=df, columns=['Gender'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"Gender_M\":\"Gender\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a quick look on Gender column, value 1 represents male and 0 represents female."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nominal Data\n",
    "They are two methods to perform feature engineering for nominal data:\n",
    "### Label Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of our data\n",
    "df_encode = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encode['Department'] = label_encoder.fit_transform(df_encode['Department'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encode.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label encoding uses alphabetical ordering. The values in 'Department' column will result in the following order :<br>\n",
    "<b>Finance > Human Resource > IT > Sales</b><br>\n",
    "\n",
    "Department names do not have an order or rank. When label encoding is performed, it will create order relationship between the categories. Thus, label encoding is less preferred when transforming nominal data. It is most commonly used to transform target variable only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data=df, columns=['Department'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenges of One-Hot Encoding**\n",
    "* Expands feature space\n",
    "* Many features may look identical, this will lead to redundant information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal data\n",
    "Data that introduces an order between them for example grade, review or ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dictionary for mapping the ordinal numerical value\n",
    "education_dict = {'SPM':1, 'Diploma':2, 'Degree':3}\n",
    "\n",
    "# Assigning ordinal numerical value to all types of education\n",
    "df['Education'] = df['Education'].map(education_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is best practice to manually convert variables to numeric values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"numeric\">Numeric data\n",
    "Categorize values in Age columns according to their age stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice age values\n",
    "df['Age_Group'] = pd.cut(df['Age'], bins=[0, 18, 25, 30, 35, 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"outlier\">Handling Outlier</a>\n",
    "## Outlier?\n",
    "Mathematically, outlier is a point which it is significant greater or lower than other data values.\n",
    "\n",
    "## Find Outlier using Boxplot\n",
    "<img src=\"https://matplotlib.org/3.2.2/_images/boxplot_explanation.png\" width=\"500\"/>\n",
    "\n",
    "[Image Source: Matplotlib](https://matplotlib.org/3.2.2/faq/howto_faq.html)\n",
    "\n",
    "## Understand Boxplot\n",
    "- Boxplot is a method to display the distribution of data\n",
    "- The Interquartile Range(IQR) indicates the range where most data is spread. We can use it to observe the spread of data. In other words, the data is concentrated in the IQR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student = df = pd.DataFrame({\n",
    "    \"Student ID\" : ['100', '101', '102', '103', '104', '105', '106', '107', '108', '109'],\n",
    "    \"Marks\" : [75, 62, 1, 66, 80, 194, 80, 90, 2, 65]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interquartile Range (IQR)\n",
    "Interquartile range, Q3-Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort in increasing order\n",
    "sorted(student['Marks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find q1(25%) and q3(75%)\n",
    "q1, q3 = np.percentile(student['Marks'],[25,75])\n",
    "print(q1, q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find IQR\n",
    "IQR = q3 - q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find lower bound and upper bound\n",
    "lower_bound = q1 - (1.5 * IQR)\n",
    "upper_bound = q3 + (1.5 * IQR)\n",
    "\n",
    "print(lower_bound, upper_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the example above, if the marks are below the lower boundary and above the upper boundary, they are considered outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "student.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize outlier in boxplot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stud_trim = student.copy() # copy so we does not make change to original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the outlier value in \"Marks\" column\n",
    "stud_trim.loc[stud_trim['Marks'] < lower_bound, 'Marks'] = np.nan\n",
    "stud_trim.loc[stud_trim['Marks'] > upper_bound, 'Marks'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stud_trim.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outlier has been successfully removed from the 'Marks' column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winsorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stud_winsor = student.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import winsorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stud_winsor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stud_winsor['Marks'] = winsorize(stud_winsor['Marks'], limits=[0.25, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stud_winsor.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stud_winsor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the table above, the dataset has been winsorized such that the extreme values (outliers) are being replaced by the lowest and highest value of our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"exercise\">Exercise\n",
    "Perform feature engineering based on dataset given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food = pd.read_csv('../data/food_preference.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>You may follow guidelines below to begin this exercise. Good luck! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 : Check if there is missing value\n",
    "food.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 : Deleting row that contain null value\n",
    "food.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 : Find unique values for categorical columns only\n",
    "\n",
    "# remove 'Timestamp' and 'Participant_ID' columns\n",
    "cat_df = food[food.columns.difference(['Timestamp', 'Participant_ID'])]\n",
    "\n",
    "# Print unique value of cat_df\n",
    "for i in cat_df.columns:\n",
    "    if cat_df.dtypes[i] == 'object':\n",
    "        print(\"Column: {}\".format(i))\n",
    "        print(cat_df[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 : Standardize Nationality values to malaysian and non-malaysian\n",
    "\n",
    "# Hint : use this values\n",
    "nationality = {\n",
    "    \"malaysian\" : \"malaysian\",\n",
    "    \"indian\" : \"non-malaysian\",\n",
    "    \"pakistani\" : \"non-malaysian\",\n",
    "    \"tanzanian\" : \"non-malaysian\",\n",
    "    \"indonesia\" : \"non-malaysian\",\n",
    "    \"pakistan\" : \"non-malaysian\",\n",
    "    \"maldivian\" : \"non-malaysian\",\n",
    "    \"my\" : \"malaysian\",\n",
    "    \"indonesian\" : \"non-malaysian\",\n",
    "    \"malaysia\" : \"malaysian\",\n",
    "    \"canadian\" : \"non-malaysian\",\n",
    "    \"nigerian\" : \"non-malaysian\",\n",
    "    \"algerian\" : \"non-malaysian\",\n",
    "    \"korean\" : \"non-malaysian\",\n",
    "    \"seychellois\" : \"non-malaysian\",\n",
    "    \"indonesain\" : \"non-malaysian\",\n",
    "    \"japan\" : \"non-malaysian\",\n",
    "    \"china\" : \"non-malaysian\",\n",
    "    \"mauritian\" : \"non-malaysian\",\n",
    "    \"yemen\" : \"non-malaysian\"\n",
    "}\n",
    "\n",
    "# Start your solution here\n",
    "food[\"Nationality\"] = food[\"Nationality\"].apply(str.lower).apply(str.strip).apply(lambda x:nationality[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 : Perform feature engineering for the rest of categorical data\n",
    "\n",
    "cat_df = food[food.columns.difference(['Timestamp', 'Participant_ID', 'Age'])]\n",
    "\n",
    "# Start your solution here\n",
    "food = pd.get_dummies(food, columns=cat_df.columns, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6(Bonus) : Extract date from 'Timestamp column'\n",
    "\n",
    "import datetime\n",
    "# Hint : New date format %d%m%Y\n",
    "\n",
    "def date_convert(date_to_convert):\n",
    "    try:\n",
    "        return datetime.datetime.strptime(date_to_convert, \"%Y/%m/%d %H:%M:%S %p GMT+8\").strftime('%d/%m/%Y')\n",
    "    except:\n",
    "        return \"Error\"\n",
    "\n",
    "# Start your solution here\n",
    "food['new_date'] = food['Timestamp'].apply(date_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, now you have a better understanding of how to include feature engineering in your project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Readings\n",
    "* <a href=https://heartbeat.comet.ml/hands-on-with-feature-engineering-techniques-encoding-categorical-variables-be4bc0715394>More feature engineering techniques</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
